{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:OpenAI client initialized successfully\n",
      "INFO:root:Grok client initialized successfully\n",
      "INFO:root:Venice client initialized successfully\n",
      "INFO:root:OpenAI client initialized successfully\n",
      "INFO:root:Grok client initialized successfully\n",
      "INFO:root:Venice client initialized successfully\n",
      "INFO:monitoring:Literal AI monitoring initialized successfully\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:monitoring:Created monitoring thread with ID: a27d4cfa-e1fe-486f-878f-6d915bb36da4\n",
      "Processing new data...\n",
      "INFO:run:Processing new data...\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Loading all CSV data from S3 bucket: rolling-data, prefix: data\n",
      "INFO:data_ops:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n",
      "INFO:root:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in directory './data' have been removed.\n",
      "Directory './data' already exists.\n",
      "Directory './data/stratified/' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Latest date processed: 2024-01-01 00:00:00+00:00\n",
      "INFO:root:Combined data contains 10231435 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time column: posted_date_time, Strata column: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Using openai for embeddings\n",
      "INFO:run:Using openai for embeddings\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:embedding_ops:Creating knowledge base with embeddings...\n",
      "Loading CSV files: 100%|██████████| 10/10 [00:00<00:00, 237.60it/s]\n",
      "Processing articles:   0%|          | 0/100 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   1%|          | 1/100 [00:00<01:36,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   2%|▏         | 2/100 [00:01<01:02,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   3%|▎         | 3/100 [00:02<01:21,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   4%|▍         | 4/100 [00:03<01:16,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   5%|▌         | 5/100 [00:03<01:15,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   6%|▌         | 6/100 [00:04<01:06,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   7%|▋         | 7/100 [00:05<01:18,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   8%|▊         | 8/100 [00:06<01:27,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   9%|▉         | 9/100 [00:07<01:20,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  10%|█         | 10/100 [00:08<01:26,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  11%|█         | 11/100 [00:09<01:26,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  12%|█▏        | 12/100 [00:10<01:20,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  13%|█▎        | 13/100 [00:11<01:22,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  14%|█▍        | 14/100 [00:12<01:17,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  15%|█▌        | 15/100 [00:13<01:23,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  16%|█▌        | 16/100 [00:14<01:33,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  17%|█▋        | 17/100 [00:15<01:24,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  18%|█▊        | 18/100 [00:16<01:20,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  19%|█▉        | 19/100 [00:17<01:07,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  20%|██        | 20/100 [00:17<01:06,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  21%|██        | 21/100 [00:18<01:03,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  22%|██▏       | 22/100 [00:19<01:02,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  23%|██▎       | 23/100 [00:20<01:08,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  24%|██▍       | 24/100 [00:20<00:56,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  25%|██▌       | 25/100 [00:21<00:59,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  26%|██▌       | 26/100 [00:22<01:01,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  27%|██▋       | 27/100 [00:23<00:54,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  28%|██▊       | 28/100 [00:24<00:57,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  29%|██▉       | 29/100 [00:26<01:38,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  30%|███       | 30/100 [00:27<01:27,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  31%|███       | 31/100 [00:28<01:19,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  32%|███▏      | 32/100 [00:29<01:15,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  33%|███▎      | 33/100 [00:30<01:11,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  34%|███▍      | 34/100 [00:31<01:01,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  35%|███▌      | 35/100 [00:32<00:57,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  36%|███▌      | 36/100 [00:32<00:49,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  37%|███▋      | 37/100 [00:33<00:45,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  38%|███▊      | 38/100 [00:35<01:07,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  39%|███▉      | 39/100 [00:35<00:56,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  40%|████      | 40/100 [00:36<00:47,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  41%|████      | 41/100 [00:37<00:50,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  42%|████▏     | 42/100 [00:38<00:51,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  43%|████▎     | 43/100 [00:39<01:02,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  44%|████▍     | 44/100 [00:40<00:59,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  45%|████▌     | 45/100 [00:42<01:00,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  46%|████▌     | 46/100 [00:42<00:54,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  47%|████▋     | 47/100 [00:43<00:52,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  48%|████▊     | 48/100 [00:44<00:49,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  49%|████▉     | 49/100 [00:46<00:59,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  50%|█████     | 50/100 [00:47<00:54,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  51%|█████     | 51/100 [00:48<00:57,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  52%|█████▏    | 52/100 [00:49<00:48,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  53%|█████▎    | 53/100 [00:50<00:44,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  54%|█████▍    | 54/100 [00:53<01:12,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  55%|█████▌    | 55/100 [00:54<01:11,  1.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  56%|█████▌    | 56/100 [00:55<01:02,  1.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  57%|█████▋    | 57/100 [00:56<00:53,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  58%|█████▊    | 58/100 [00:57<00:47,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  59%|█████▉    | 59/100 [00:58<00:47,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  60%|██████    | 60/100 [00:59<00:42,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  61%|██████    | 61/100 [01:00<00:45,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  62%|██████▏   | 62/100 [01:02<00:44,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  63%|██████▎   | 63/100 [01:02<00:40,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  64%|██████▍   | 64/100 [01:03<00:38,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  65%|██████▌   | 65/100 [01:05<00:37,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  66%|██████▌   | 66/100 [01:06<00:37,  1.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  67%|██████▋   | 67/100 [01:06<00:30,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  68%|██████▊   | 68/100 [01:07<00:29,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  69%|██████▉   | 69/100 [01:08<00:27,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  70%|███████   | 70/100 [01:09<00:26,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  71%|███████   | 71/100 [01:10<00:29,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  72%|███████▏  | 72/100 [01:11<00:27,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  73%|███████▎  | 73/100 [01:12<00:24,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  74%|███████▍  | 74/100 [01:13<00:25,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  75%|███████▌  | 75/100 [01:14<00:23,  1.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  76%|███████▌  | 76/100 [01:15<00:22,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  77%|███████▋  | 77/100 [01:19<00:43,  1.90s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  78%|███████▊  | 78/100 [01:19<00:32,  1.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  79%|███████▉  | 79/100 [01:20<00:27,  1.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  80%|████████  | 80/100 [01:21<00:21,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  81%|████████  | 81/100 [01:22<00:22,  1.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  82%|████████▏ | 82/100 [01:23<00:18,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  83%|████████▎ | 83/100 [01:24<00:16,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  84%|████████▍ | 84/100 [01:24<00:14,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  85%|████████▌ | 85/100 [01:25<00:13,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  86%|████████▌ | 86/100 [01:27<00:14,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  87%|████████▋ | 87/100 [01:28<00:13,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  88%|████████▊ | 88/100 [01:28<00:10,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  89%|████████▉ | 89/100 [01:29<00:09,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  90%|█████████ | 90/100 [01:30<00:10,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  91%|█████████ | 91/100 [01:32<00:09,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  92%|█████████▏| 92/100 [01:32<00:07,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  93%|█████████▎| 93/100 [01:33<00:06,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  94%|█████████▍| 94/100 [01:34<00:06,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  95%|█████████▌| 95/100 [01:36<00:05,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  96%|█████████▌| 96/100 [01:36<00:03,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  97%|█████████▋| 97/100 [01:37<00:02,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  98%|█████████▊| 98/100 [01:38<00:01,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  99%|█████████▉| 99/100 [01:39<00:00,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles: 100%|██████████| 100/100 [01:40<00:00,  1.00s/it]\n",
      "INFO:embedding_ops:Successfully created knowledge base at ./data/knowledge_base.csv\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Using openai for chunk analysis\n",
      "INFO:run:Using openai for chunk analysis\n",
      "Using grok for final summary\n",
      "INFO:run:Using grok for final summary\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:inference_ops:Processing text chunks\n",
      "INFO:inference_ops:Summarizing 91 valid chunks of text\n",
      "  0%|          | 0/91 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  1%|          | 1/91 [00:06<09:37,  6.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "  2%|▏         | 2/91 [00:07<04:57,  3.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 3/91 [00:09<03:46,  2.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  5%|▌         | 5/91 [00:09<01:47,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  7%|▋         | 6/91 [00:09<01:20,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  8%|▊         | 7/91 [00:10<01:00,  1.40it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|▉         | 9/91 [00:14<01:51,  1.35s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 11%|█         | 10/91 [00:14<01:28,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 12%|█▏        | 11/91 [00:14<01:08,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 13%|█▎        | 12/91 [00:14<00:52,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 15%|█▌        | 14/91 [00:15<00:40,  1.89it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 16%|█▋        | 15/91 [00:17<00:57,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 18%|█▊        | 16/91 [00:18<01:00,  1.25it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 19%|█▊        | 17/91 [00:20<01:27,  1.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|█▉        | 18/91 [00:21<01:24,  1.15s/it]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 21%|██        | 19/91 [00:22<01:15,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 22%|██▏       | 20/91 [00:22<01:03,  1.11it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 23%|██▎       | 21/91 [00:23<01:03,  1.11it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 24%|██▍       | 22/91 [00:24<01:05,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 26%|██▋       | 24/91 [00:25<00:51,  1.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      " 27%|██▋       | 25/91 [00:26<00:42,  1.55it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 29%|██▊       | 26/91 [00:28<01:07,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|██▉       | 27/91 [00:28<00:54,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 31%|███       | 28/91 [00:29<00:49,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 32%|███▏      | 29/91 [00:29<00:45,  1.37it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 30/91 [00:30<00:42,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 31/91 [00:31<00:43,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 35%|███▌      | 32/91 [00:31<00:38,  1.55it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 36%|███▋      | 33/91 [00:32<00:36,  1.59it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 37%|███▋      | 34/91 [00:32<00:36,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 38%|███▊      | 35/91 [00:33<00:43,  1.28it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|███▉      | 36/91 [00:35<00:50,  1.09it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 41%|████      | 37/91 [00:36<00:51,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 42%|████▏     | 38/91 [00:36<00:37,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 43%|████▎     | 39/91 [00:37<00:43,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 44%|████▍     | 40/91 [00:37<00:35,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 46%|████▌     | 42/91 [00:38<00:23,  2.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 47%|████▋     | 43/91 [00:38<00:18,  2.56it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 48%|████▊     | 44/91 [00:40<00:35,  1.32it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 49%|████▉     | 45/91 [00:42<00:52,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 52%|█████▏    | 47/91 [00:42<00:29,  1.50it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 53%|█████▎    | 48/91 [00:43<00:26,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 54%|█████▍    | 49/91 [00:43<00:28,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 55%|█████▍    | 50/91 [00:44<00:24,  1.66it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 56%|█████▌    | 51/91 [00:44<00:20,  2.00it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 57%|█████▋    | 52/91 [00:46<00:33,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 58%|█████▊    | 53/91 [00:47<00:31,  1.21it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 59%|█████▉    | 54/91 [00:48<00:37,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 55/91 [00:48<00:27,  1.31it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 62%|██████▏   | 56/91 [00:49<00:25,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 63%|██████▎   | 57/91 [00:49<00:22,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 64%|██████▎   | 58/91 [00:49<00:17,  1.91it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 65%|██████▍   | 59/91 [00:51<00:23,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 66%|██████▌   | 60/91 [00:51<00:17,  1.79it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 67%|██████▋   | 61/91 [00:51<00:13,  2.30it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 68%|██████▊   | 62/91 [00:53<00:25,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 69%|██████▉   | 63/91 [00:54<00:25,  1.08it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 64/91 [00:55<00:27,  1.03s/it]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 71%|███████▏  | 65/91 [00:56<00:25,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 74%|███████▎  | 67/91 [00:57<00:15,  1.60it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 75%|███████▍  | 68/91 [00:57<00:14,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 76%|███████▌  | 69/91 [00:58<00:14,  1.52it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 77%|███████▋  | 70/91 [01:00<00:23,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 78%|███████▊  | 71/91 [01:01<00:18,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 79%|███████▉  | 72/91 [01:01<00:15,  1.19it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 73/91 [01:02<00:15,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 81%|████████▏ | 74/91 [01:03<00:16,  1.04it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 82%|████████▏ | 75/91 [01:04<00:15,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 84%|████████▎ | 76/91 [01:05<00:11,  1.36it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 86%|████████▌ | 78/91 [01:05<00:07,  1.65it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 87%|████████▋ | 79/91 [01:06<00:08,  1.45it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 89%|████████▉ | 81/91 [01:09<00:09,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 82/91 [01:10<00:07,  1.17it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 91%|█████████ | 83/91 [01:12<00:09,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 92%|█████████▏| 84/91 [01:12<00:06,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 93%|█████████▎| 85/91 [01:13<00:05,  1.06it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 95%|█████████▍| 86/91 [01:14<00:04,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 96%|█████████▌| 87/91 [01:14<00:02,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 88/91 [01:15<00:02,  1.20it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 98%|█████████▊| 89/91 [01:16<00:01,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 99%|█████████▉| 90/91 [01:17<00:00,  1.15it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 91/91 [01:18<00:00,  1.16it/s]\n",
      "INFO:inference_ops:Generating final summary\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.x.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "WARNING:monitoring:Operation exceeded duration threshold\n",
      "WARNING:monitoring:Low confidence score detected\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Temporal Overview\n",
      "Time Range: 2024-11-04 09:34:19 to 2025-01-01 12:01:18\n",
      "Active Periods: \n",
      "- **Syrian Conflict Developments**: A spike in activity around discussions on territorial changes and military movements in Syria.\n",
      "- **Cryptocurrency Market Speculation**: Increased engagement in threads discussing XRP and LINK's potential market roles.\n",
      "- **AI and Tech Discussions**: Notable activity in threads discussing AI development trends and their societal implications.\n",
      "\n",
      "Thread Distribution: \n",
      "- Threads on geopolitical events, particularly the Syrian conflict, show high activity and reach due to their real-time nature and broad implications.\n",
      "- Cryptocurrency threads exhibit moderate activity with potential for increased engagement if linked to market movements.\n",
      "- Technology and AI discussions are spread across multiple threads, indicating a broad interest but varied engagement levels.\n",
      "\n",
      "Key Correlations: \n",
      "- **Syrian Conflict Developments** correlate with increased discussions on international relations and military technology.\n",
      "- **Cryptocurrency Market Speculation** shows potential correlation with broader financial technology trends.\n",
      "- **AI and Tech Discussions** are linked to ongoing debates about AI ethics and societal impact.\n",
      "\n",
      "### 2. Thread Analysis\n",
      "#### A. Key Metrics\n",
      "[Activity & Reach]\n",
      "- (2024-11-05T12:00:00Z, \"Syrian Conflict Developments\", activity_rate, 0.85, 0.70)\n",
      "- (2024-11-06T10:30:00Z, \"Cryptocurrency Market Speculation\", cross_thread_spread, 0.65, 0.85)\n",
      "\n",
      "[Impact & Quality]\n",
      "- (2024-11-05T12:00:00Z, \"Syrian Conflict Developments\", influence_score, 0.75, 0.80)\n",
      "- (2024-11-07T09:45:00Z, \"AI and Tech Discussions\", toxicity_level, 0.45, 0.90)\n",
      "- (2024-11-08T14:20:00Z, \"Cryptocurrency Market Speculation\", information_novelty, 0.65, 0.75)\n",
      "\n",
      "#### B. Pattern Summary\n",
      "* Activity: The sequence of events begins with **Syrian Conflict Developments**, followed by **Cryptocurrency Market Speculation**, and then **AI and Tech Discussions**, indicating a shift from geopolitical to economic and technological topics.\n",
      "* Influence: **Syrian Conflict Developments** have a significant cross-event impact, influencing discussions on international relations and military technology.\n",
      "* Credibility: The credibility of claims in **Syrian Conflict Developments** is moderate due to reliance on unverified sources, while **Cryptocurrency Market Speculation** shows low credibility due to speculative nature.\n",
      "* Anomalies: An unusual pattern in **AI and Tech Discussions** is the high toxicity level, which could deter constructive dialogue.\n",
      "\n",
      "### 3. Content Analysis\n",
      "#### A. Key Claims\n",
      "[Primary Claims]\n",
      "- (2024-11-05T12:00:00Z, \"Syrian Conflict Developments\", \"Bashar al-Assad reportedly fled to Tehran\", 0.50, 0.75)\n",
      "  - Supporting evidence: References to Syrian telegram channels and live maps.\n",
      "  - Cross-references: Linked to **Military Technology Speculation**.\n",
      "- (2024-11-06T10:30:00Z, \"Cryptocurrency Market Speculation\", \"XRP could reach $10K if it takes over SWIFT's market share\", 0.40, 0.60)\n",
      "  - Supporting evidence: Speculative market analysis.\n",
      "  - Cross-references: Connected to **Financial Technology Trends**.\n",
      "\n",
      "[Risk Factors]\n",
      "* Toxicity: **AI and Tech Discussions** show a chain of toxic exchanges due to controversial claims about AI development.\n",
      "* Community: **Cryptocurrency Market Speculation** attracts a community of investors and enthusiasts, potentially leading to misinformation.\n",
      "* Moderation: **Syrian Conflict Developments** may require moderation to prevent the spread of misinformation and propaganda.\n",
      "\n",
      "#### B. Viral Assessment\n",
      "* Spread Rate: (\"Syrian Conflict Developments\", velocity, 0.70, reach, 0.80)\n",
      "* Catalysts: **Syrian Conflict Developments** are triggered by reports of high-profile figures fleeing and significant military movements.\n",
      "* Cross-Platform: **Cryptocurrency Market Speculation** could gain traction if linked to mainstream financial news or reports.\n",
      "\n",
      "### 4. Forecasts\n",
      "#### A. 24h Outlook\n",
      "[Activity]\n",
      "- (2024-11-06T12:00:00Z, \"Syrian Conflict Developments Forecast\", 0.75, [0.65, 0.85])\n",
      "  - Expected triggers: Further military movements or political changes in Syria.\n",
      "  - Impacts: Increased discussion on international relations and potential humanitarian crises.\n",
      "\n",
      "[Risk]\n",
      "- (2024-11-06T12:00:00Z, \"AI and Tech Discussions Risk\", 0.60, [0.45, 0.75])\n",
      "  - Potential escalation paths: Increased toxicity if controversial AI claims gain more attention.\n",
      "\n",
      "#### B. 72h Trends\n",
      "[Patterns]\n",
      "- (2024-11-08T12:00:00Z, \"Cryptocurrency Market Speculation Trend\", 0.65, [0.55, 0.75])\n",
      "  - Pattern evolution forecast: Increased discussion if market movements validate speculative claims.\n",
      "\n",
      "[Interventions]\n",
      "* Recommended Points: **Syrian Conflict Developments** may require moderation to manage misinformation.\n",
      "* Stability Metrics: **AI and Tech Discussions** show moderate stability due to potential for varying interpretations.\n",
      "* Uncertainty Factors: **Cryptocurrency Market Speculation** depends on external market developments and news coverage.\n"
     ]
    }
   ],
   "source": [
    "from run import run_knowledge_agents\n",
    "from model_ops import ModelOperation, ModelProvider\n",
    "\n",
    "query = \"\"\"\n",
    "<temporal_context>\n",
    "- Immediate Events (past 24 hours): Capture real-time developments\n",
    "- Recent Patterns (past 72 hours): Identify emerging narratives\n",
    "- Weekly Trends (past 7 days): Track pattern formation\n",
    "- Monthly Context (past 30 days): Establish baseline trends\n",
    "</temporal_context>\n",
    "\n",
    "<focus_areas>\n",
    "1. Technology & Innovation:\n",
    "   - Breakthrough announcements and validation metrics\n",
    "   - Product launches with market reception data\n",
    "   - Research developments with citation patterns\n",
    "   - Industry shifts with quantifiable impacts\n",
    "\n",
    "2. Economic & Market Dynamics:\n",
    "   - Market movements with volatility indicators\n",
    "   - Economic indicators with historical comparisons\n",
    "   - Policy impacts with measured outcomes\n",
    "   - Industry transformations with adoption rates\n",
    "\n",
    "3. Social & Cultural Impact:\n",
    "   - Public discourse with sentiment metrics\n",
    "   - Social movements with participation trends\n",
    "   - Cultural phenomena with diffusion patterns\n",
    "   - Community responses with engagement data\n",
    "\n",
    "4. Policy & Governance:\n",
    "   - Regulatory changes with compliance metrics\n",
    "   - Political developments with stability indicators\n",
    "   - International relations with diplomatic indices\n",
    "   - Policy implementations with effectiveness measures\n",
    "\n",
    "5. Narrative Analysis:\n",
    "   - Information flow patterns\n",
    "   - Discourse evolution metrics\n",
    "   - Cross-domain influence measures\n",
    "   - Stability indicators\n",
    "</focus_areas>\n",
    "\n",
    "<analysis_requirements>\n",
    "1. Temporal Analysis:\n",
    "   - Extract time-series data points (tx, vx)\n",
    "   - Document temporal dependencies\n",
    "   - Map causal chains\n",
    "\n",
    "2. Pattern Recognition:\n",
    "   - Identify cyclical patterns\n",
    "   - Document correlation strengths\n",
    "   - Flag regime changes\n",
    "\n",
    "3. Contextual Integration:\n",
    "   - Map narrative networks\n",
    "   - Track information propagation\n",
    "   - Measure cross-domain effects\n",
    "\n",
    "4. Forecast Requirements:\n",
    "   - Generate confidence intervals\n",
    "   - Project trend trajectories\n",
    "   - Identify stability thresholds\n",
    "</analysis_requirements>\n",
    "\"\"\"\n",
    "providers = {\n",
    "    ModelOperation.EMBEDDING: ModelProvider.OPENAI,\n",
    "    ModelOperation.CHUNK_GENERATION: ModelProvider.OPENAI,\n",
    "    ModelOperation.SUMMARIZATION: ModelProvider.GROK}\n",
    "\n",
    "chunks, summary = run_knowledge_agents(\n",
    "    query=query,\n",
    "    process_new=True,\n",
    "    providers=providers)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:OpenAI client initialized successfully\n",
      "INFO:root:Grok client initialized successfully\n",
      "INFO:root:Venice client initialized successfully\n",
      "INFO:root:OpenAI client initialized successfully\n",
      "INFO:root:Grok client initialized successfully\n",
      "INFO:root:Venice client initialized successfully\n",
      "INFO:monitoring:Literal AI monitoring initialized successfully\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:monitoring:Created monitoring thread with ID: 1a109e0e-5898-40da-b7d0-b599f8c994a0\n",
      "Processing new data...\n",
      "INFO:run:Processing new data...\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Loading all CSV data from S3 bucket: rolling-data, prefix: data\n",
      "INFO:data_ops:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n",
      "INFO:root:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in directory './data' have been removed.\n",
      "Directory './data' already exists.\n",
      "Directory './data/stratified/' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Latest date processed: 2024-01-01 00:00:00+00:00\n",
      "INFO:root:Combined data contains 10307654 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time column: posted_date_time, Strata column: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Using openai for embeddings\n",
      "INFO:run:Using openai for embeddings\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:embedding_ops:Creating knowledge base with embeddings...\n",
      "Loading CSV files: 100%|██████████| 11/11 [00:00<00:00, 88.73it/s]\n",
      "Processing articles:   0%|          | 0/10 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  10%|█         | 1/10 [00:04<00:36,  4.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  20%|██        | 2/10 [00:07<00:28,  3.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  30%|███       | 3/10 [00:10<00:24,  3.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  40%|████      | 4/10 [00:14<00:22,  3.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  50%|█████     | 5/10 [00:18<00:18,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  60%|██████    | 6/10 [00:23<00:16,  4.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  70%|███████   | 7/10 [00:26<00:11,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  80%|████████  | 8/10 [00:28<00:06,  3.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  90%|█████████ | 9/10 [00:33<00:03,  3.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles: 100%|██████████| 10/10 [00:39<00:00,  3.97s/it]\n",
      "INFO:embedding_ops:Successfully created knowledge base at ./data/knowledge_base.csv\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Using openai for chunk analysis\n",
      "INFO:run:Using openai for chunk analysis\n",
      "Using openai for final summary\n",
      "INFO:run:Using openai for final summary\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:inference_ops:Processing text chunks\n",
      "INFO:inference_ops:Summarizing 94 valid chunks of text\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  1%|          | 1/94 [00:04<07:31,  4.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  2%|▏         | 2/94 [00:05<03:12,  2.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 3/94 [00:05<01:52,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  4%|▍         | 4/94 [00:05<01:20,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  6%|▋         | 6/94 [00:05<00:44,  1.99it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  7%|▋         | 7/94 [00:09<01:53,  1.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  9%|▊         | 8/94 [00:09<01:29,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|▉         | 9/94 [00:09<01:09,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 11%|█         | 10/94 [00:10<00:52,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 13%|█▎        | 12/94 [00:10<00:34,  2.37it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 14%|█▍        | 13/94 [00:14<01:41,  1.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 17%|█▋        | 16/94 [00:14<00:53,  1.47it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 18%|█▊        | 17/94 [00:15<00:55,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 19%|█▉        | 18/94 [00:15<00:45,  1.68it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 19/94 [00:16<00:39,  1.88it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 21%|██▏       | 20/94 [00:19<01:26,  1.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 22%|██▏       | 21/94 [00:19<01:09,  1.05it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 23%|██▎       | 22/94 [00:19<00:55,  1.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 24%|██▍       | 23/94 [00:20<00:49,  1.43it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 26%|██▌       | 24/94 [00:20<00:39,  1.77it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 27%|██▋       | 25/94 [00:20<00:30,  2.29it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 28%|██▊       | 26/94 [00:22<00:58,  1.16it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 29%|██▊       | 27/94 [00:23<01:00,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|██▉       | 28/94 [00:24<00:53,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 31%|███       | 29/94 [00:24<00:52,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 32%|███▏      | 30/94 [00:25<00:38,  1.66it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 31/94 [00:25<00:41,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 32/94 [00:25<00:30,  2.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 35%|███▌      | 33/94 [00:26<00:39,  1.53it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 36%|███▌      | 34/94 [00:28<00:59,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      " 37%|███▋      | 35/94 [00:29<00:50,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 38%|███▊      | 36/94 [00:29<00:43,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 39%|███▉      | 37/94 [00:29<00:33,  1.70it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 43%|████▎     | 40/94 [00:30<00:15,  3.42it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 44%|████▎     | 41/94 [00:31<00:28,  1.83it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 45%|████▍     | 42/94 [00:32<00:31,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 46%|████▌     | 43/94 [00:33<00:33,  1.54it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 47%|████▋     | 44/94 [00:33<00:31,  1.59it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 49%|████▉     | 46/94 [00:34<00:20,  2.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 47/94 [00:34<00:22,  2.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 52%|█████▏    | 49/94 [00:36<00:30,  1.49it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 53%|█████▎    | 50/94 [00:36<00:25,  1.71it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 54%|█████▍    | 51/94 [00:38<00:32,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 55%|█████▌    | 52/94 [00:38<00:28,  1.46it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 56%|█████▋    | 53/94 [00:39<00:26,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 57%|█████▋    | 54/94 [00:39<00:21,  1.88it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 59%|█████▊    | 55/94 [00:39<00:16,  2.38it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 61%|██████    | 57/94 [00:42<00:28,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 62%|██████▏   | 58/94 [00:42<00:22,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      " 63%|██████▎   | 59/94 [00:42<00:22,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 64%|██████▍   | 60/94 [00:43<00:18,  1.89it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 65%|██████▍   | 61/94 [00:43<00:17,  1.92it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 66%|██████▌   | 62/94 [00:44<00:17,  1.81it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 67%|██████▋   | 63/94 [00:45<00:21,  1.44it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 68%|██████▊   | 64/94 [00:45<00:20,  1.49it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 66/94 [00:47<00:18,  1.53it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 71%|███████▏  | 67/94 [00:47<00:16,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 72%|███████▏  | 68/94 [00:48<00:16,  1.58it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 73%|███████▎  | 69/94 [00:49<00:18,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 74%|███████▍  | 70/94 [00:50<00:18,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 76%|███████▌  | 71/94 [00:50<00:14,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 77%|███████▋  | 72/94 [00:50<00:11,  1.98it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 78%|███████▊  | 73/94 [00:51<00:09,  2.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 79%|███████▊  | 74/94 [00:51<00:11,  1.74it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      " 80%|███████▉  | 75/94 [00:52<00:10,  1.78it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 81%|████████  | 76/94 [00:52<00:08,  2.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 82%|████████▏ | 77/94 [00:54<00:12,  1.41it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 83%|████████▎ | 78/94 [00:54<00:11,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 84%|████████▍ | 79/94 [00:55<00:12,  1.24it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 85%|████████▌ | 80/94 [00:56<00:09,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 86%|████████▌ | 81/94 [00:56<00:07,  1.74it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 88%|████████▊ | 83/94 [00:58<00:08,  1.31it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 89%|████████▉ | 84/94 [00:58<00:06,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 85/94 [00:58<00:04,  1.91it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 91%|█████████▏| 86/94 [01:00<00:06,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 93%|█████████▎| 87/94 [01:00<00:04,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 94%|█████████▎| 88/94 [01:01<00:03,  1.89it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 96%|█████████▌| 90/94 [01:01<00:01,  2.63it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 91/94 [01:04<00:03,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 98%|█████████▊| 92/94 [01:04<00:01,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 99%|█████████▉| 93/94 [01:05<00:00,  1.29it/s]INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 94/94 [01:07<00:00,  1.40it/s]\n",
      "INFO:inference_ops:Generating final summary\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "WARNING:monitoring:Operation exceeded duration threshold\n",
      "WARNING:monitoring:Low confidence score detected\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Temporal Overview\n",
      "\n",
      "**Time Range:** 2024-11-03 09:37:52 to 2025-01-01 16:44:23\n",
      "\n",
      "**Active Periods:**\n",
      "- **Financial Strategies Discussion:** Notable activity spike around discussions on financial security and market strategies.\n",
      "- **Cryptocurrency Speculation:** Increased activity linked to speculative discussions about Bitcoin and other cryptocurrencies.\n",
      "- **Political Influence Threads:** Spikes in activity related to political donations and their implications on policy.\n",
      "\n",
      "**Thread Distribution:**\n",
      "- High engagement in threads discussing cryptocurrency, particularly Bitcoin, Ethereum, and Solana.\n",
      "- Moderate distribution across threads involving political and financial strategy discussions.\n",
      "\n",
      "**Key Correlations:**\n",
      "- **Bitcoin Investment Discussions** are often correlated with broader market speculation threads.\n",
      "- **Political Donation Threads** show a correlation with discussions on military appointments and policy implications.\n",
      "\n",
      "### 2. Thread Analysis\n",
      "\n",
      "#### A. Key Metrics\n",
      "\n",
      "[Activity & Reach]\n",
      "- (2024-12-15T14:00:00Z, \"Cryptocurrency Speculation\", activity_rate, 0.75, 0.80)\n",
      "- (2024-12-20T10:30:00Z, \"Political Influence Threads\", cross_thread_spread, 0.65, 0.85)\n",
      "\n",
      "[Impact & Quality]\n",
      "- (2024-12-18T09:00:00Z, \"Bitcoin Investment Discussions\", influence_score, 0.70, 0.75)\n",
      "- (2024-12-22T16:45:00Z, \"Financial Strategies Discussion\", toxicity_level, -0.20, 0.60)\n",
      "- (2024-12-25T11:15:00Z, \"Political Donation Threads\", information_novelty, 0.60, 0.70)\n",
      "\n",
      "#### B. Pattern Summary\n",
      "\n",
      "* **Activity:** \n",
      "   - Financial strategies and cryptocurrency speculation show consistent spikes in activity.\n",
      "   - Political threads demonstrate periodic bursts linked to external events or news.\n",
      "\n",
      "* **Influence:** \n",
      "   - Cryptocurrency discussions have a notable cross-thread influence due to their speculative nature.\n",
      "   - Political donation threads impact related discussions on policy and governance.\n",
      "\n",
      "* **Credibility:** \n",
      "   - Financial strategy threads generally maintain moderate credibility due to user expertise sharing.\n",
      "   - Political threads vary in credibility based on the sources cited.\n",
      "\n",
      "* **Anomalies:** \n",
      "   - Unusual spikes in toxicity within certain political threads suggest potential misinformation or inflammatory content.\n",
      "\n",
      "### 3. Content Analysis\n",
      "\n",
      "#### A. Key Claims\n",
      "\n",
      "[Primary Claims]\n",
      "- (2024-12-18T09:00:00Z, \"Bitcoin Investment Discussions\", claim, moderate_credibility, high_impact)\n",
      "   - Supporting evidence links to broader market speculation events.\n",
      "   - Cross-references with financial strategy discussions highlight investment trends.\n",
      "\n",
      "[Risk Factors]\n",
      "* **Toxicity:** \n",
      "   - Political donation threads exhibit chains of toxic exchanges potentially requiring moderation.\n",
      "* **Community:** \n",
      "   - Cryptocurrency communities show high engagement but risk speculative misinformation.\n",
      "* **Moderation:** \n",
      "   - Intervention may be needed in politically charged threads with high toxicity levels.\n",
      "\n",
      "#### B. Viral Assessment\n",
      "\n",
      "* **Spread Rate:** (\"Cryptocurrency Speculation\", high_velocity, broad_reach)\n",
      "* **Catalysts:** Market movements and influential figures act as primary triggers for increased engagement.\n",
      "* **Cross-Platform:** External signals from financial news platforms amplify cryptocurrency discussions.\n",
      "\n",
      "### 4. Forecasts\n",
      "\n",
      "#### A. 24h Outlook\n",
      "\n",
      "[Activity]\n",
      "- (t+24h, \"Cryptocurrency Speculation_forecast\", 0.80, [0.70, 0.90])\n",
      "   - Expected triggers include significant market movements or announcements from influential figures.\n",
      "\n",
      "[Risk]\n",
      "- (t+24h, \"Political Influence Threads_risk\", 0.65, [0.55, 0.75])\n",
      "   - Potential escalation paths linked to ongoing political debates or new revelations.\n",
      "\n",
      "#### B. 72h Trends\n",
      "\n",
      "[Patterns]\n",
      "- (t+72h, \"Financial Strategies Trend\", 0.70, [0.60, 0.80])\n",
      "   - Forecast suggests continued interest in secure investment strategies amidst market volatility.\n",
      "\n",
      "[Interventions]\n",
      "* Recommended Points:\n",
      "   - Monitor cryptocurrency speculation for misinformation risks.\n",
      "   - Address toxicity in political threads through moderation if necessary.\n",
      "* Stability Metrics:\n",
      "   - Based on consistent activity patterns in financial and cryptocurrency discussions.\n",
      "* Uncertainty Factors:\n",
      "   - Dependent on external economic developments and political news cycles impacting thread dynamics.\n"
     ]
    }
   ],
   "source": [
    "from run import run_knowledge_agents\n",
    "from model_ops import ModelOperation, ModelProvider\n",
    "\n",
    "query = \"\"\"\n",
    "<temporal_context>\n",
    "- Immediate Events (past 24 hours): Capture real-time developments\n",
    "- Recent Patterns (past 72 hours): Identify emerging narratives\n",
    "- Weekly Trends (past 7 days): Track pattern formation\n",
    "- Monthly Context (past 30 days): Establish baseline trends\n",
    "</temporal_context>\n",
    "\n",
    "<focus_areas>\n",
    "Investment opportunity analysis in sectors such as AI, crypto, and energy.\n",
    "</focus_areas>\n",
    "\n",
    "<analysis_requirements>\n",
    "\n",
    "1. Asset specificity:\n",
    "   - Always track Bitcoin, Ethereum, and Solana. \n",
    "   - Always choose a 4th asset for analysis.\n",
    "   \n",
    "3. Requirements:\n",
    "   - Document correlation strengths\n",
    "   - News sentiment\n",
    "   - Market sentiment\n",
    "   - Social media sentiment\n",
    "   - Your prediction\n",
    "   - Confidence intervals\n",
    "    \n",
    "</analysis_requirements>\n",
    "\"\"\"\n",
    "providers = {\n",
    "    ModelOperation.EMBEDDING: ModelProvider.OPENAI,\n",
    "    ModelOperation.CHUNK_GENERATION: ModelProvider.OPENAI,\n",
    "    ModelOperation.SUMMARIZATION: ModelProvider.OPENAI}\n",
    "\n",
    "chunks, summary = run_knowledge_agents(\n",
    "    query=query,\n",
    "    process_new=True,\n",
    "    batch_size=100,\n",
    "    providers=providers)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:monitoring:Literal AI monitoring initialized successfully\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:monitoring:Created monitoring thread with ID: 7e338802-2f88-4e07-9ff0-ff5b0b7db850\n",
      "Processing new data...\n",
      "INFO:run:Processing new data...\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Loading all CSV data from S3 bucket: rolling-data, prefix: data\n",
      "INFO:data_ops:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n",
      "INFO:root:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in directory './data' have been removed.\n",
      "Directory './data' already exists.\n",
      "Directory './data/stratified/' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Latest date processed: 2024-01-01 00:00:00+00:00\n",
      "INFO:root:Combined data contains 10234333 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time column: posted_date_time, Strata column: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Using openai for embeddings\n",
      "INFO:run:Using openai for embeddings\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:embedding_ops:Creating knowledge base with embeddings...\n",
      "Loading CSV files: 100%|██████████| 10/10 [00:00<00:00, 243.85it/s]\n",
      "Processing articles:   0%|          | 0/100 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   1%|          | 1/100 [00:00<01:27,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   2%|▏         | 2/100 [00:01<01:19,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   3%|▎         | 3/100 [00:02<01:30,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   4%|▍         | 4/100 [00:03<01:39,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   5%|▌         | 5/100 [00:04<01:28,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   6%|▌         | 6/100 [00:05<01:31,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   7%|▋         | 7/100 [00:06<01:24,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   8%|▊         | 8/100 [00:07<01:12,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   9%|▉         | 9/100 [00:08<01:26,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  10%|█         | 10/100 [00:09<01:23,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  11%|█         | 11/100 [00:09<01:16,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  12%|█▏        | 12/100 [00:10<01:10,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  13%|█▎        | 13/100 [00:11<01:12,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  14%|█▍        | 14/100 [00:12<01:18,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  15%|█▌        | 15/100 [00:16<02:30,  1.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  16%|█▌        | 16/100 [00:20<03:25,  2.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  17%|█▋        | 17/100 [00:20<02:36,  1.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  18%|█▊        | 18/100 [00:21<02:07,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  19%|█▉        | 19/100 [00:22<01:38,  1.22s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  20%|██        | 20/100 [00:23<01:28,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  21%|██        | 21/100 [00:23<01:13,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  22%|██▏       | 22/100 [00:24<01:08,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  23%|██▎       | 23/100 [00:25<01:06,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  24%|██▍       | 24/100 [00:26<01:10,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  25%|██▌       | 25/100 [00:27<01:15,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  26%|██▌       | 26/100 [00:28<01:09,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  27%|██▋       | 27/100 [00:28<00:58,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  28%|██▊       | 28/100 [00:29<01:04,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  29%|██▉       | 29/100 [00:30<01:01,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  30%|███       | 30/100 [00:31<00:52,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  31%|███       | 31/100 [00:31<00:54,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  32%|███▏      | 32/100 [00:33<01:05,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  33%|███▎      | 33/100 [00:34<01:09,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  34%|███▍      | 34/100 [00:35<01:05,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  35%|███▌      | 35/100 [00:36<01:05,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  36%|███▌      | 36/100 [00:37<00:59,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  37%|███▋      | 37/100 [00:38<01:01,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  38%|███▊      | 38/100 [00:39<00:58,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  39%|███▉      | 39/100 [00:39<00:52,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  40%|████      | 40/100 [00:40<00:48,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  41%|████      | 41/100 [00:41<00:46,  1.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  42%|████▏     | 42/100 [00:42<00:58,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  43%|████▎     | 43/100 [00:46<01:44,  1.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  44%|████▍     | 44/100 [00:47<01:34,  1.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  45%|████▌     | 45/100 [00:48<01:16,  1.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  46%|████▌     | 46/100 [00:49<01:05,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  47%|████▋     | 47/100 [00:50<01:01,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  48%|████▊     | 48/100 [00:51<00:54,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  49%|████▉     | 49/100 [00:52<00:54,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  50%|█████     | 50/100 [00:53<00:54,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  51%|█████     | 51/100 [00:54<00:57,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  52%|█████▏    | 52/100 [00:55<00:54,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  53%|█████▎    | 53/100 [00:56<00:52,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  54%|█████▍    | 54/100 [00:57<00:45,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  55%|█████▌    | 55/100 [00:59<00:50,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  56%|█████▌    | 56/100 [00:59<00:45,  1.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  57%|█████▋    | 57/100 [01:00<00:43,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  58%|█████▊    | 58/100 [01:01<00:43,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  59%|█████▉    | 59/100 [01:02<00:39,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  60%|██████    | 60/100 [01:03<00:37,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  61%|██████    | 61/100 [01:04<00:33,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  62%|██████▏   | 62/100 [01:05<00:32,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  63%|██████▎   | 63/100 [01:05<00:31,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  64%|██████▍   | 64/100 [01:06<00:32,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  65%|██████▌   | 65/100 [01:07<00:31,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  66%|██████▌   | 66/100 [01:08<00:32,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  67%|██████▋   | 67/100 [01:09<00:29,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  68%|██████▊   | 68/100 [01:11<00:36,  1.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  69%|██████▉   | 69/100 [01:12<00:34,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  70%|███████   | 70/100 [01:13<00:32,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  71%|███████   | 71/100 [01:14<00:29,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  72%|███████▏  | 72/100 [01:15<00:28,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  73%|███████▎  | 73/100 [01:16<00:27,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  74%|███████▍  | 74/100 [01:17<00:24,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  75%|███████▌  | 75/100 [01:18<00:23,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  76%|███████▌  | 76/100 [01:18<00:20,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  77%|███████▋  | 77/100 [01:19<00:17,  1.29it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  78%|███████▊  | 78/100 [01:20<00:17,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  79%|███████▉  | 79/100 [01:21<00:16,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  80%|████████  | 80/100 [01:21<00:16,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  81%|████████  | 81/100 [01:23<00:18,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  82%|████████▏ | 82/100 [01:24<00:18,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  83%|████████▎ | 83/100 [01:25<00:18,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  84%|████████▍ | 84/100 [01:26<00:15,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  85%|████████▌ | 85/100 [01:27<00:13,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  86%|████████▌ | 86/100 [01:28<00:13,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  87%|████████▋ | 87/100 [01:29<00:12,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  88%|████████▊ | 88/100 [01:30<00:11,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  89%|████████▉ | 89/100 [01:31<00:10,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  90%|█████████ | 90/100 [01:32<00:10,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  91%|█████████ | 91/100 [01:33<00:09,  1.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  92%|█████████▏| 92/100 [01:34<00:08,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  93%|█████████▎| 93/100 [01:34<00:06,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  94%|█████████▍| 94/100 [01:35<00:05,  1.11it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  95%|█████████▌| 95/100 [01:36<00:04,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  96%|█████████▌| 96/100 [01:37<00:03,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  97%|█████████▋| 97/100 [01:38<00:02,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  98%|█████████▊| 98/100 [01:39<00:01,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  99%|█████████▉| 99/100 [01:40<00:00,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles: 100%|██████████| 100/100 [01:41<00:00,  1.01s/it]\n",
      "INFO:embedding_ops:Successfully created knowledge base at ./data/knowledge_base.csv\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "Using openai for chunk analysis\n",
      "INFO:run:Using openai for chunk analysis\n",
      "Using grok for final summary\n",
      "INFO:run:Using grok for final summary\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:inference_ops:Processing text chunks\n",
      "INFO:inference_ops:Summarizing 91 valid chunks of text\n",
      "  0%|          | 0/91 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  1%|          | 1/91 [00:09<14:23,  9.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  2%|▏         | 2/91 [00:09<05:59,  4.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 3/91 [00:10<03:33,  2.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  4%|▍         | 4/91 [00:10<02:17,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  5%|▌         | 5/91 [00:11<01:43,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  8%|▊         | 7/91 [00:12<01:12,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  9%|▉         | 8/91 [00:15<01:59,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|▉         | 9/91 [00:15<01:32,  1.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 11%|█         | 10/91 [00:16<01:22,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 12%|█▏        | 11/91 [00:16<01:06,  1.21it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 13%|█▎        | 12/91 [00:16<00:49,  1.61it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 14%|█▍        | 13/91 [00:17<00:54,  1.44it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 15%|█▌        | 14/91 [00:19<01:31,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 16%|█▋        | 15/91 [00:20<01:21,  1.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 18%|█▊        | 16/91 [00:20<01:00,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 19%|█▊        | 17/91 [00:22<01:14,  1.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|█▉        | 18/91 [00:23<01:20,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 21%|██        | 19/91 [00:24<01:03,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 22%|██▏       | 20/91 [00:25<01:12,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 23%|██▎       | 21/91 [00:28<01:49,  1.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 24%|██▍       | 22/91 [00:28<01:23,  1.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 25%|██▌       | 23/91 [00:29<01:05,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 26%|██▋       | 24/91 [00:29<00:49,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 27%|██▋       | 25/91 [00:29<00:45,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 29%|██▊       | 26/91 [00:30<00:46,  1.41it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|██▉       | 27/91 [00:31<00:52,  1.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 31%|███       | 28/91 [00:31<00:40,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 32%|███▏      | 29/91 [00:34<01:07,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 30/91 [00:35<01:14,  1.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 31/91 [00:36<01:10,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 35%|███▌      | 32/91 [00:37<01:07,  1.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 36%|███▋      | 33/91 [00:38<00:52,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 38%|███▊      | 35/91 [00:39<00:42,  1.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|███▉      | 36/91 [00:39<00:33,  1.64it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 41%|████      | 37/91 [00:41<00:50,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 42%|████▏     | 38/91 [00:42<00:53,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 43%|████▎     | 39/91 [00:43<00:49,  1.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 44%|████▍     | 40/91 [00:44<00:48,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 45%|████▌     | 41/91 [00:44<00:36,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 46%|████▌     | 42/91 [00:44<00:29,  1.69it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 47%|████▋     | 43/91 [00:45<00:29,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 48%|████▊     | 44/91 [00:45<00:24,  1.89it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 49%|████▉     | 45/91 [00:47<00:39,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 51%|█████     | 46/91 [00:47<00:28,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 52%|█████▏    | 47/91 [00:48<00:31,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 53%|█████▎    | 48/91 [00:48<00:28,  1.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 54%|█████▍    | 49/91 [00:51<00:48,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 55%|█████▍    | 50/91 [00:51<00:35,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 56%|█████▌    | 51/91 [00:51<00:25,  1.54it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 58%|█████▊    | 53/91 [00:51<00:17,  2.22it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 59%|█████▉    | 54/91 [00:53<00:24,  1.52it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 55/91 [00:55<00:35,  1.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 63%|██████▎   | 57/91 [00:56<00:31,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 64%|██████▎   | 58/91 [00:57<00:26,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 65%|██████▍   | 59/91 [00:57<00:23,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 66%|██████▌   | 60/91 [00:58<00:21,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 68%|██████▊   | 62/91 [01:00<00:24,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 69%|██████▉   | 63/91 [01:00<00:20,  1.38it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 64/91 [01:02<00:25,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 71%|███████▏  | 65/91 [01:03<00:28,  1.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 73%|███████▎  | 66/91 [01:04<00:25,  1.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 74%|███████▎  | 67/91 [01:05<00:21,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 76%|███████▌  | 69/91 [01:05<00:14,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 77%|███████▋  | 70/91 [01:07<00:16,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 78%|███████▊  | 71/91 [01:09<00:22,  1.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 79%|███████▉  | 72/91 [01:09<00:16,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 73/91 [01:09<00:12,  1.39it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 81%|████████▏ | 74/91 [01:09<00:09,  1.80it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 82%|████████▏ | 75/91 [01:10<00:08,  2.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 84%|████████▎ | 76/91 [01:11<00:09,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 85%|████████▍ | 77/91 [01:12<00:11,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 86%|████████▌ | 78/91 [01:13<00:12,  1.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 87%|████████▋ | 79/91 [01:14<00:09,  1.31it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 88%|████████▊ | 80/91 [01:14<00:06,  1.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 89%|████████▉ | 81/91 [01:15<00:08,  1.12it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 82/91 [01:16<00:07,  1.15it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 92%|█████████▏| 84/91 [01:16<00:03,  1.98it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 93%|█████████▎| 85/91 [01:18<00:04,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 95%|█████████▍| 86/91 [01:19<00:04,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 96%|█████████▌| 87/91 [01:20<00:03,  1.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 88/91 [01:21<00:02,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 98%|█████████▊| 89/91 [01:22<00:01,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 99%|█████████▉| 90/91 [01:25<00:01,  1.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 91/91 [01:25<00:00,  1.06it/s]\n",
      "INFO:inference_ops:Generating final summary\n",
      "INFO:httpx:HTTP Request: POST https://api.x.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "WARNING:monitoring:Operation exceeded duration threshold\n",
      "WARNING:monitoring:Low confidence score detected\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cloud.getliteral.ai/api/graphql \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Temporal Overview\n",
      "Time Range: 2024-11-04 18:05:17 to 2024-12-31 20:08:25\n",
      "\n",
      "**Active Periods:**\n",
      "- **Cryptocurrency Market Movements**: Spikes in activity related to discussions on Bitcoin and altcoins, particularly around price movements and investment strategies.\n",
      "- **Geopolitical Discussions**: Increased engagement on threads discussing geopolitical tensions and predictions, notably around Eurasian dynamics and economic policies.\n",
      "- **Tech Industry Shifts**: Notable activity around discussions on tech industry trends, including mergers and shifts in manufacturing.\n",
      "\n",
      "**Thread Distribution:**\n",
      "- Threads are distributed across various topics, with a concentration on financial markets, geopolitical events, and technology sectors. Cryptocurrency threads show higher persistence and reach, indicating sustained interest.\n",
      "\n",
      "**Key Correlations:**\n",
      "- **Cryptocurrency Market Movements** correlate with **Geopolitical Discussions**, as economic policies and global events influence market sentiment.\n",
      "- **Tech Industry Shifts** are linked to broader discussions on economic policies, reflecting the impact of industry changes on economic forecasts.\n",
      "\n",
      "### 2. Thread Analysis\n",
      "\n",
      "#### A. Key Metrics\n",
      "\n",
      "**[Activity & Reach]**\n",
      "- (2024-11-05T10:00:00Z, \"Cryptocurrency Market Movements\", activity_rate, 0.85, 0.70)\n",
      "- (2024-11-06T14:30:00Z, \"Geopolitical Discussions\", cross_thread_spread, 0.65, 0.85)\n",
      "\n",
      "**[Impact & Quality]**\n",
      "- (2024-11-05T10:00:00Z, \"Cryptocurrency Market Movements\", influence_score, 0.70, 0.80)\n",
      "- (2024-11-07T09:00:00Z, \"Tech Industry Shifts\", toxicity_level, 0.30, 0.90)\n",
      "- (2024-11-08T12:00:00Z, \"Geopolitical Discussions\", information_novelty, 0.50, 0.75)\n",
      "\n",
      "#### B. Pattern Summary\n",
      "- **Activity**: The sequence of events shows a pattern from **Cryptocurrency Market Movements** to **Geopolitical Discussions**, suggesting a linkage between market sentiment and global events.\n",
      "- **Influence**: **Tech Industry Shifts** have a cross-event impact, influencing discussions on economic policies and market dynamics.\n",
      "- **Credibility**: Threads on **Cryptocurrency Market Movements** show moderate credibility due to the mix of anecdotal evidence and market data.\n",
      "- **Anomalies**: The thread on **3-day SMO** stands out due to its high novelty score but low current engagement, indicating potential for future interest.\n",
      "\n",
      "### 3. Content Analysis\n",
      "\n",
      "#### A. Key Claims\n",
      "\n",
      "**[Primary Claims]**\n",
      "- (2024-11-05T10:00:00Z, \"Cryptocurrency Market Movements\", \"Bitcoin is a bubble\", 0.60, 0.70)\n",
      "  - Supporting evidence: Linked to broader market sentiment shifts.\n",
      "  - Cross-references: Connected to **Geopolitical Discussions** due to economic policy impacts.\n",
      "- (2024-11-06T14:30:00Z, \"Geopolitical Discussions\", \"Eurasian geopolitical dynamics will escalate\", 0.50, 0.65)\n",
      "  - Supporting evidence: Historical patterns and current events.\n",
      "  - Cross-references: Linked to **Tech Industry Shifts** due to potential economic repercussions.\n",
      "\n",
      "**[Risk Factors]**\n",
      "- **Toxicity**: Threads on **Geopolitical Discussions** show potential for escalating toxicity due to inflammatory language.\n",
      "- **Community**: Responses to **Tech Industry Shifts** indicate a mix of skepticism and support, reflecting community polarization.\n",
      "- **Moderation**: Increased moderation may be needed for threads discussing **Cryptocurrency Market Movements** to manage speculative behavior and misinformation.\n",
      "\n",
      "#### B. Viral Assessment\n",
      "- **Spread Rate**: (\"Cryptocurrency Market Movements\", velocity, 0.75, reach, 0.65)\n",
      "- **Catalysts**: **Geopolitical Discussions** act as catalysts for increased engagement in cryptocurrency threads.\n",
      "- **Cross-Platform**: Discussions on **Tech Industry Shifts** may influence external platforms, particularly those focused on tech news and analysis.\n",
      "\n",
      "### 4. Forecasts\n",
      "\n",
      "#### A. 24h Outlook\n",
      "\n",
      "**[Activity]**\n",
      "- (2024-11-06T10:00:00Z, \"Cryptocurrency Market Movements Forecast\", 0.75, [0.65, 0.85])\n",
      "  - Expected triggers: Market volatility or significant news events.\n",
      "  - Impacts: Increased discussion and potential speculative behavior.\n",
      "\n",
      "**[Risk]**\n",
      "- (2024-11-06T10:00:00Z, \"Geopolitical Discussions Risk\", 0.60, [0.45, 0.75])\n",
      "  - Potential escalation paths: Increased toxicity if discussions become more polarized.\n",
      "\n",
      "#### B. 72h Trends\n",
      "\n",
      "**[Patterns]**\n",
      "- (2024-11-08T10:00:00Z, \"Tech Industry Shifts Trend\", 0.70, [0.60, 0.80])\n",
      "  - Pattern evolution forecast: Continued discussion with potential for increased focus on specific companies or sectors.\n",
      "\n",
      "**[Interventions]**\n",
      "- **Recommended Points**: Increased moderation for **Cryptocurrency Market Movements** to manage speculative behavior.\n",
      "- **Stability Metrics**: **Tech Industry Shifts** show moderate stability, likely to persist as part of broader economic conversations.\n",
      "- **Uncertainty Factors**: **Geopolitical Discussions** depend on external geopolitical developments, adding uncertainty to their impact.\n"
     ]
    }
   ],
   "source": [
    "from run import run_knowledge_agents\n",
    "from model_ops import ModelOperation, ModelProvider\n",
    "\n",
    "query = \"\"\"<temporal_context>\n",
    "- Real-time Market Dynamics (past 24 hours): Capture price movements, volume patterns, and sentiment shifts\n",
    "- Short-term Trends (past 72 hours): Track momentum and narrative development\n",
    "- Medium-term Patterns (past 7 days): Identify market regime changes and sector rotations\n",
    "- Long-term Context (past 30 days): Establish baseline market conditions and macro trends\n",
    "</temporal_context>\n",
    "\n",
    "<focus_areas>\n",
    "1. Market Structure Analysis:\n",
    "   - Liquidity conditions and market depth\n",
    "   - Institutional vs retail flow patterns\n",
    "   - Cross-asset correlations\n",
    "   - Market microstructure changes\n",
    "\n",
    "2. Risk-Return Dynamics:\n",
    "   - Volatility term structure\n",
    "   - Risk premium evolution\n",
    "   - Systematic risk factors\n",
    "   - Market inefficiencies and anomalies\n",
    "\n",
    "3. Sentiment & Positioning:\n",
    "   - Crowd sentiment metrics\n",
    "   - Positioning extremes\n",
    "   - Narrative momentum\n",
    "   - Consensus divergence\n",
    "\n",
    "4. Macro Environment:\n",
    "   - Monetary policy expectations\n",
    "   - Fiscal policy impacts\n",
    "   - Global capital flows\n",
    "   - Regulatory landscape shifts\n",
    "\n",
    "5. Innovation & Disruption:\n",
    "   - Technology adoption curves\n",
    "   - Business model evolution\n",
    "   - Industry value chain shifts\n",
    "   - Competitive dynamics\n",
    "</focus_areas>\n",
    "\n",
    "<analysis_requirements>\n",
    "1. Signal Extraction:\n",
    "   - Price-volume relationships\n",
    "   - Sentiment-flow correlations\n",
    "   - Cross-sectional patterns\n",
    "   - Regime change indicators\n",
    "\n",
    "2. Risk Assessment:\n",
    "   - Tail risk probabilities\n",
    "   - Correlation breakdowns\n",
    "   - Liquidity conditions\n",
    "   - Systemic risk factors\n",
    "\n",
    "3. Opportunity Identification:\n",
    "   - Value-momentum divergence\n",
    "   - Narrative-price disconnects\n",
    "   - Structural inefficiencies\n",
    "   - Mean reversion potential\n",
    "\n",
    "4. Forecast Parameters:\n",
    "   - Confidence intervals by timeframe\n",
    "   - Scenario probabilities\n",
    "   - Position sizing signals\n",
    "   - Risk-adjusted return expectations\n",
    "</analysis_requirements>\"\"\"\n",
    "\n",
    "providers = {\n",
    "    ModelOperation.EMBEDDING: ModelProvider.OPENAI,\n",
    "    ModelOperation.CHUNK_GENERATION: ModelProvider.OPENAI,\n",
    "    ModelOperation.SUMMARIZATION: ModelProvider.GROK\n",
    "}\n",
    "\n",
    "chunks, summary = run_knowledge_agents(\n",
    "    query=query,\n",
    "    process_new=True,\n",
    "    providers=providers\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
