{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:OpenAI client initialized successfully\n",
      "INFO:root:Grok client initialized successfully\n",
      "INFO:root:Venice client initialized successfully\n",
      "INFO:root:OpenAI client initialized successfully\n",
      "INFO:root:Grok client initialized successfully\n",
      "INFO:root:Venice client initialized successfully\n",
      "Configuration loaded successfully\n",
      "INFO:run:Configuration loaded successfully\n",
      "Processing new data...\n",
      "INFO:run:Processing new data...\n",
      "INFO:root:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in directory './data' have been removed.\n",
      "Directory './data' already exists.\n",
      "Directory './data/stratified/' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Latest date processed: 2024-12-26 00:00:00+00:00\n",
      "INFO:root:Combined data contains 6229940 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time column: posted_date_time, Strata column: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using openai for embeddings\n",
      "INFO:run:Using openai for embeddings\n",
      "INFO:embedding_ops:Creating knowledge base with embeddings...\n",
      "Loading CSV files: 100%|██████████| 12/12 [00:00<00:00, 75.80it/s]\n",
      "Processing articles:   0%|          | 0/48 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   2%|▏         | 1/48 [00:03<02:33,  3.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   4%|▍         | 2/48 [00:06<02:33,  3.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   6%|▋         | 3/48 [00:11<03:05,  4.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   8%|▊         | 4/48 [00:14<02:43,  3.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  10%|█         | 5/48 [00:17<02:23,  3.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  12%|█▎        | 6/48 [00:20<02:15,  3.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  15%|█▍        | 7/48 [00:24<02:23,  3.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  17%|█▋        | 8/48 [00:27<02:14,  3.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  19%|█▉        | 9/48 [00:30<01:59,  3.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  21%|██        | 10/48 [00:32<01:53,  2.98s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  23%|██▎       | 11/48 [00:35<01:50,  2.99s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  25%|██▌       | 12/48 [00:42<02:23,  3.98s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  27%|██▋       | 13/48 [00:44<02:08,  3.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  29%|██▉       | 14/48 [00:47<01:52,  3.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  31%|███▏      | 15/48 [00:51<01:56,  3.52s/it]INFO:openai._base_client:Retrying request to /embeddings in 0.824390 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  33%|███▎      | 16/48 [01:05<03:34,  6.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  35%|███▌      | 17/48 [01:09<02:58,  5.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  38%|███▊      | 18/48 [01:12<02:30,  5.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  40%|███▉      | 19/48 [01:15<02:09,  4.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  42%|████▏     | 20/48 [01:17<01:46,  3.80s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  44%|████▍     | 21/48 [01:20<01:33,  3.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  46%|████▌     | 22/48 [01:23<01:29,  3.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  48%|████▊     | 23/48 [01:27<01:23,  3.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  50%|█████     | 24/48 [01:30<01:20,  3.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  52%|█████▏    | 25/48 [01:33<01:14,  3.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  54%|█████▍    | 26/48 [01:36<01:11,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  56%|█████▋    | 27/48 [01:39<01:04,  3.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  58%|█████▊    | 28/48 [01:42<01:03,  3.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  60%|██████    | 29/48 [01:45<00:57,  3.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  62%|██████▎   | 30/48 [01:48<00:52,  2.92s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  65%|██████▍   | 31/48 [01:50<00:48,  2.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  67%|██████▋   | 32/48 [01:56<00:59,  3.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  69%|██████▉   | 33/48 [01:59<00:52,  3.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  71%|███████   | 34/48 [02:02<00:46,  3.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  73%|███████▎  | 35/48 [02:05<00:41,  3.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  75%|███████▌  | 36/48 [02:08<00:37,  3.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  77%|███████▋  | 37/48 [02:11<00:36,  3.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  79%|███████▉  | 38/48 [02:15<00:33,  3.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  81%|████████▏ | 39/48 [02:18<00:30,  3.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  83%|████████▎ | 40/48 [02:26<00:36,  4.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  85%|████████▌ | 41/48 [02:29<00:28,  4.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  88%|████████▊ | 42/48 [02:32<00:22,  3.78s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  90%|████████▉ | 43/48 [02:35<00:18,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  92%|█████████▏| 44/48 [02:39<00:15,  3.80s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  94%|█████████▍| 45/48 [02:42<00:10,  3.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  96%|█████████▌| 46/48 [02:45<00:06,  3.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  98%|█████████▊| 47/48 [02:50<00:03,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles: 100%|██████████| 48/48 [02:53<00:00,  3.62s/it]\n",
      "INFO:embedding_ops:Successfully created knowledge base at ./data/knowledge_base.csv\n",
      "Using openai for chunk analysis\n",
      "INFO:run:Using openai for chunk analysis\n",
      "Using grok for final summary\n",
      "INFO:run:Using grok for final summary\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:inference_ops:Processing text chunks\n",
      "INFO:inference_ops:Summarizing 93 valid chunks of text\n",
      "  0%|          | 0/93 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  1%|          | 1/93 [00:05<09:08,  5.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  2%|▏         | 2/93 [00:06<03:50,  2.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 3/93 [00:06<02:11,  1.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  4%|▍         | 4/93 [00:06<01:26,  1.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  5%|▌         | 5/93 [00:06<01:00,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  6%|▋         | 6/93 [00:07<01:13,  1.18it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  8%|▊         | 7/93 [00:08<01:07,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  9%|▊         | 8/93 [00:09<01:15,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|▉         | 9/93 [00:12<02:00,  1.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 11%|█         | 10/93 [00:12<01:26,  1.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 12%|█▏        | 11/93 [00:12<01:05,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 13%|█▎        | 12/93 [00:13<01:09,  1.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 14%|█▍        | 13/93 [00:14<00:59,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 15%|█▌        | 14/93 [00:14<00:49,  1.59it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 16%|█▌        | 15/93 [00:14<00:39,  2.00it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 17%|█▋        | 16/93 [00:16<01:09,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 18%|█▊        | 17/93 [00:17<01:11,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 19%|█▉        | 18/93 [00:18<01:00,  1.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 19/93 [00:18<00:50,  1.47it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 22%|██▏       | 20/93 [00:19<01:06,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 23%|██▎       | 21/93 [00:20<00:57,  1.25it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 24%|██▎       | 22/93 [00:20<00:50,  1.40it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 25%|██▍       | 23/93 [00:22<01:03,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 27%|██▋       | 25/93 [00:22<00:36,  1.88it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 28%|██▊       | 26/93 [00:25<01:15,  1.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 29%|██▉       | 27/93 [00:25<00:57,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|███       | 28/93 [00:25<00:47,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 31%|███       | 29/93 [00:26<00:41,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 32%|███▏      | 30/93 [00:26<00:35,  1.80it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 31/93 [00:26<00:29,  2.09it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 32/93 [00:27<00:29,  2.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 35%|███▌      | 33/93 [00:29<01:01,  1.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 37%|███▋      | 34/93 [00:30<00:59,  1.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 39%|███▊      | 36/93 [00:30<00:33,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|███▉      | 37/93 [00:31<00:27,  2.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 41%|████      | 38/93 [00:31<00:21,  2.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 42%|████▏     | 39/93 [00:33<00:42,  1.26it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 43%|████▎     | 40/93 [00:34<00:49,  1.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 44%|████▍     | 41/93 [00:35<00:55,  1.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 45%|████▌     | 42/93 [00:36<00:48,  1.05it/s]INFO:openai._base_client:Retrying request to /chat/completions in 0.807924 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 46%|████▌     | 43/93 [00:36<00:38,  1.28it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 47%|████▋     | 44/93 [00:36<00:28,  1.73it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 48%|████▊     | 45/93 [00:37<00:21,  2.24it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 51%|█████     | 47/93 [00:38<00:27,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 52%|█████▏    | 48/93 [00:40<00:43,  1.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 53%|█████▎    | 49/93 [00:41<00:35,  1.23it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 54%|█████▍    | 50/93 [00:41<00:32,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 55%|█████▍    | 51/93 [00:42<00:26,  1.57it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 56%|█████▌    | 52/93 [00:42<00:26,  1.56it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 58%|█████▊    | 54/93 [00:43<00:23,  1.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 59%|█████▉    | 55/93 [00:44<00:26,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 56/93 [00:45<00:21,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 61%|██████▏   | 57/93 [00:45<00:18,  1.99it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 62%|██████▏   | 58/93 [00:47<00:29,  1.20it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 63%|██████▎   | 59/93 [00:47<00:21,  1.59it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 65%|██████▍   | 60/93 [00:48<00:24,  1.34it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 67%|██████▋   | 62/93 [00:48<00:17,  1.76it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 68%|██████▊   | 63/93 [00:49<00:14,  2.05it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 69%|██████▉   | 64/93 [00:49<00:11,  2.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|██████▉   | 65/93 [00:50<00:20,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 71%|███████   | 66/93 [00:51<00:18,  1.48it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 72%|███████▏  | 67/93 [00:52<00:22,  1.14it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 73%|███████▎  | 68/93 [00:52<00:16,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 74%|███████▍  | 69/93 [00:53<00:15,  1.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 75%|███████▌  | 70/93 [00:53<00:12,  1.88it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 76%|███████▋  | 71/93 [00:54<00:12,  1.71it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 77%|███████▋  | 72/93 [00:56<00:17,  1.17it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 78%|███████▊  | 73/93 [00:56<00:12,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|███████▉  | 74/93 [00:56<00:12,  1.58it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 81%|████████  | 75/93 [00:58<00:16,  1.06it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 82%|████████▏ | 76/93 [00:58<00:11,  1.44it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 83%|████████▎ | 77/93 [00:59<00:11,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 84%|████████▍ | 78/93 [00:59<00:08,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 85%|████████▍ | 79/93 [01:01<00:11,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 86%|████████▌ | 80/93 [01:01<00:08,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 87%|████████▋ | 81/93 [01:02<00:08,  1.37it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 88%|████████▊ | 82/93 [01:03<00:09,  1.19it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 89%|████████▉ | 83/93 [01:03<00:07,  1.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 84/93 [01:04<00:06,  1.46it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 91%|█████████▏| 85/93 [01:04<00:04,  1.94it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 92%|█████████▏| 86/93 [01:05<00:04,  1.42it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 95%|█████████▍| 88/93 [01:06<00:02,  1.89it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 96%|█████████▌| 89/93 [01:06<00:01,  2.01it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 90/93 [01:07<00:01,  2.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 98%|█████████▊| 91/93 [01:08<00:01,  1.36it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 99%|█████████▉| 92/93 [01:09<00:00,  1.35it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 93/93 [01:09<00:00,  1.33it/s]\n",
      "INFO:inference_ops:Generating final summary\n",
      "INFO:httpx:HTTP Request: POST https://api.x.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Summary generated successfully\n",
      "INFO:run:Summary generated successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Temporal Overview\n",
      "**Time Range:** 2024-12-27 01:47:07 to 2024-12-29 11:19:11\n",
      "\n",
      "**Active Periods:**\n",
      "- **High Activity Spike:** The thread discussing the unusually high number of \"twitter-react\" threads (event4) showed significant activity on 2024-12-27T06:52:12Z, indicating a surge in discussions related to Twitter reactions.\n",
      "- **Moderate Activity:** Threads related to political unrest in India (event1) and the potential impact of Elon Musk's actions (event10) showed consistent engagement over the period, with notable spikes on 2024-12-27T13:36:55Z and 2024-12-27T10:24:55Z respectively.\n",
      "\n",
      "**Thread Distribution:**\n",
      "- Threads were distributed across various topics, with a notable concentration on geopolitical issues, cryptocurrency speculation, and cultural critiques. The distribution suggests a diverse range of interests among users, with some threads gaining more traction due to their controversial nature or involvement of high-profile figures.\n",
      "\n",
      "**Key Correlations:**\n",
      "- There is a correlation between threads discussing Elon Musk (event5, event10) and those related to cryptocurrency speculation (event16), suggesting Musk's influence on market discussions.\n",
      "- Threads discussing political unrest in India (event1) and anti-India sentiment (event17) show a potential correlation, indicating a broader narrative around geopolitical tensions.\n",
      "\n",
      "### 2. Thread Analysis\n",
      "\n",
      "#### A. Key Metrics\n",
      "\n",
      "**[Activity & Reach]**\n",
      "- (2024-12-27T06:52:12Z, \"The presence of 49 twitter-react threads indicates a significant surge in discussions related to Twitter reactions\", activity_rate, 0.85, 0.75)\n",
      "- (2024-12-27T13:36:55Z, \"The thread raises concerns about political unrest and brain drain in India\", cross_thread_spread, 0.40, 0.65)\n",
      "\n",
      "**[Impact & Quality]**\n",
      "- (2024-12-27T14:09:59Z, \"The perceived decline of Zionist influence and the rise of a racial dialectic opposing high-skilled immigration\", influence_score, 0.85, 0.80)\n",
      "- (2024-12-27T23:20:27Z, \"The timing of buying and selling Bitcoin based on past halving events\", toxicity_level, 0.20, 0.50)\n",
      "- (2024-12-27T22:15:19Z, \"The significant event involving AI and Elon Musk perceived as impactful within the /POL/ community\", information_novelty, 0.80, 0.75)\n",
      "\n",
      "#### B. Pattern Summary\n",
      "- **Activity:** The sequence of events shows a pattern where discussions around high-profile figures like Elon Musk (event5, event10) often precede or coincide with increased activity in related threads, such as those discussing cryptocurrency (event16).\n",
      "- **Influence:** Threads discussing geopolitical issues (event1, event17) have a cross-event impact, influencing discussions on related topics like immigration and cultural shifts.\n",
      "- **Credibility:** The credibility of claims varies, with threads like those discussing market predictions (event16) having low credibility due to speculative nature, while threads with historical references (event8) have moderate credibility.\n",
      "- **Anomalies:** The unusually high number of \"twitter-react\" threads (event4) is an anomaly, suggesting a unique event or trend that could be a catalyst for further discussions.\n",
      "\n",
      "### 3. Content Analysis\n",
      "\n",
      "#### A. Key Claims\n",
      "\n",
      "**[Primary Claims]**\n",
      "- (2024-12-27T13:36:55Z, \"The thread raises concerns about political unrest and brain drain in India\", moderate, 0.40)\n",
      "  - Supporting evidence: Linked to discussions on anti-India sentiment (event17)\n",
      "  - Cross-references: Connected to threads discussing geopolitical tensions (event14)\n",
      "\n",
      "- (2024-12-27T14:09:59Z, \"The perceived decline of Zionist influence and the rise of a racial dialectic opposing high-skilled immigration\", low, 0.85)\n",
      "  - Supporting evidence: Linked to discussions on immigration policies (event20)\n",
      "  - Cross-references: Connected to threads discussing cultural shifts (event7)\n",
      "\n",
      "**[Risk Factors]**\n",
      "- **Toxicity:** Threads with high toxicity levels include those discussing racial dialectics (event15) and conspiracy theories (event25), which could lead to toxic event chains if not moderated.\n",
      "- **Community:** The community response to threads like those discussing Elon Musk (event5) shows a mix of skepticism and excitement, indicating a polarized community.\n",
      "- **Moderation:** Threads with high toxicity and potential for misinformation (event25, event15) require immediate moderation to prevent escalation.\n",
      "\n",
      "#### B. Viral Assessment\n",
      "- **Spread Rate:** (\"The presence of 49 twitter-react threads indicates a significant surge in discussions related to Twitter reactions\", velocity, 0.70, reach, 0.75)\n",
      "- **Catalysts:** The mention of Elon Musk in various contexts (event5, event10) acts as a catalyst for increased engagement and spread across threads.\n",
      "- **Cross-Platform:** Discussions around cryptocurrency (event16) and geopolitical tensions (event14) show potential for cross-platform signals, as these topics are widely discussed on other platforms.\n",
      "\n",
      "### 4. Forecasts\n",
      "\n",
      "#### A. 24h Outlook\n",
      "\n",
      "**[Activity]**\n",
      "- (2024-12-30T06:52:12Z, \"The presence of 49 twitter-react threads indicates a significant surge in discussions related to Twitter reactions\", 0.75, [0.65, 0.85])\n",
      "  - Expected triggers and impacts: Continued high engagement due to the novelty and potential for further Twitter-related events.\n",
      "\n",
      "- (2024-12-30T13:36:55Z, \"The thread raises concerns about political unrest and brain drain in India\", 0.60, [0.50, 0.70])\n",
      "  - Expected triggers and impacts: Increased activity if new developments or news related to political unrest in India emerge.\n",
      "\n",
      "**[Risk]**\n",
      "- (2024-12-30T14:09:59Z, \"The perceived decline of Zionist influence and the rise of a racial dialectic opposing high-skilled immigration\", 0.70, [0.60, 0.80])\n",
      "  - Potential escalation paths: Risk of increased toxicity and misinformation if the discussion becomes more polarized.\n",
      "\n",
      "- (2024-12-30T22:15:19Z, \"The significant event involving AI and Elon Musk perceived as impactful within the /POL/ community\", 0.65, [0.55, 0.75])\n",
      "  - Potential escalation paths: Risk of speculative claims and misinformation spreading if not moderated.\n",
      "\n",
      "#### B. 72h Trends\n",
      "\n",
      "**[Patterns]**\n",
      "- (2024-12-31T14:09:59Z, \"The perceived decline of Zionist influence and the rise of a racial dialectic opposing high-skilled immigration\", 0.60, [0.50, 0.70])\n",
      "  - Pattern evolution forecast: Potential for increased discussions on immigration policies and cultural shifts.\n",
      "\n",
      "- (2024-12-31T22:15:19Z, \"The significant event involving AI and Elon Musk perceived as impactful within the /POL/ community\", 0.55, [0.45, 0.65])\n",
      "  - Pattern evolution forecast: Continued interest in AI and Elon Musk's influence, potentially leading to broader discussions on technology and market dynamics.\n",
      "\n",
      "**[Interventions]**\n",
      "- **Recommended Points:** Immediate moderation is recommended for threads discussing racial dialectics (event15) and conspiracy theories (event25) to prevent toxic escalation.\n",
      "- **Stability Metrics:** The stability of threads discussing geopolitical issues (event1, event14) is moderate, with potential for fluctuations based on external events.\n",
      "- **Uncertainty Factors:** The impact of threads related to Elon Musk (event5, event10) is highly uncertain due to the volatile nature of public interest in his actions and statements.\n"
     ]
    }
   ],
   "source": [
    "from run import run_knowledge_agents\n",
    "from model_ops import ModelOperation, ModelProvider\n",
    "\n",
    "query = \"\"\"\n",
    "<temporal_context>\n",
    "- Immediate Events (past 24 hours): Capture real-time developments\n",
    "- Recent Patterns (past 72 hours): Identify emerging narratives\n",
    "- Weekly Trends (past 7 days): Track pattern formation\n",
    "- Monthly Context (past 30 days): Establish baseline trends\n",
    "</temporal_context>\n",
    "\n",
    "<focus_areas>\n",
    "1. Technology & Innovation:\n",
    "   - Breakthrough announcements and validation metrics\n",
    "   - Product launches with market reception data\n",
    "   - Research developments with citation patterns\n",
    "   - Industry shifts with quantifiable impacts\n",
    "\n",
    "2. Economic & Market Dynamics:\n",
    "   - Market movements with volatility indicators\n",
    "   - Economic indicators with historical comparisons\n",
    "   - Policy impacts with measured outcomes\n",
    "   - Industry transformations with adoption rates\n",
    "\n",
    "3. Social & Cultural Impact:\n",
    "   - Public discourse with sentiment metrics\n",
    "   - Social movements with participation trends\n",
    "   - Cultural phenomena with diffusion patterns\n",
    "   - Community responses with engagement data\n",
    "\n",
    "4. Policy & Governance:\n",
    "   - Regulatory changes with compliance metrics\n",
    "   - Political developments with stability indicators\n",
    "   - International relations with diplomatic indices\n",
    "   - Policy implementations with effectiveness measures\n",
    "\n",
    "5. Narrative Analysis:\n",
    "   - Information flow patterns\n",
    "   - Discourse evolution metrics\n",
    "   - Cross-domain influence measures\n",
    "   - Stability indicators\n",
    "</focus_areas>\n",
    "\n",
    "<analysis_requirements>\n",
    "1. Temporal Analysis:\n",
    "   - Extract time-series data points (tx, vx)\n",
    "   - Document temporal dependencies\n",
    "   - Map causal chains\n",
    "\n",
    "2. Pattern Recognition:\n",
    "   - Identify cyclical patterns\n",
    "   - Document correlation strengths\n",
    "   - Flag regime changes\n",
    "\n",
    "3. Contextual Integration:\n",
    "   - Map narrative networks\n",
    "   - Track information propagation\n",
    "   - Measure cross-domain effects\n",
    "\n",
    "4. Forecast Requirements:\n",
    "   - Generate confidence intervals\n",
    "   - Project trend trajectories\n",
    "   - Identify stability thresholds\n",
    "</analysis_requirements>\n",
    "\"\"\"\n",
    "providers = {\n",
    "    ModelOperation.EMBEDDING: ModelProvider.OPENAI,\n",
    "    ModelOperation.CHUNK_GENERATION: ModelProvider.OPENAI,\n",
    "    ModelOperation.SUMMARIZATION: ModelProvider.GROK}\n",
    "\n",
    "chunks, summary = run_knowledge_agents(\n",
    "    query=query,\n",
    "    process_new=True,\n",
    "    providers=providers)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully\n",
      "INFO:run:Configuration loaded successfully\n",
      "Processing new data...\n",
      "INFO:run:Processing new data...\n",
      "INFO:root:Loading all CSV data from S3 bucket: rolling-data, prefix: data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in directory './data' have been removed.\n",
      "Directory './data' already exists.\n",
      "Directory './data/stratified/' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Latest date processed: 2024-12-26 00:00:00+00:00\n",
      "INFO:root:Combined data contains 6234454 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time column: posted_date_time, Strata column: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using openai for embeddings\n",
      "INFO:run:Using openai for embeddings\n",
      "INFO:embedding_ops:Creating knowledge base with embeddings...\n",
      "Loading CSV files: 100%|██████████| 10/10 [00:00<00:00, 60.11it/s]\n",
      "Processing articles:   0%|          | 0/25 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   4%|▍         | 1/25 [00:07<03:11,  7.97s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:   8%|▊         | 2/25 [00:16<03:04,  8.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  12%|█▏        | 3/25 [00:28<03:38,  9.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  16%|█▌        | 4/25 [00:36<03:14,  9.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  20%|██        | 5/25 [00:42<02:41,  8.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  24%|██▍       | 6/25 [00:48<02:21,  7.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  28%|██▊       | 7/25 [00:57<02:24,  8.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  32%|███▏      | 8/25 [01:04<02:09,  7.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  36%|███▌      | 9/25 [01:07<01:39,  6.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  40%|████      | 10/25 [01:11<01:20,  5.36s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  44%|████▍     | 11/25 [01:16<01:13,  5.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  48%|████▊     | 12/25 [01:24<01:18,  6.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  52%|█████▏    | 13/25 [01:32<01:20,  6.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  56%|█████▌    | 14/25 [01:37<01:08,  6.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  60%|██████    | 15/25 [01:43<01:00,  6.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  64%|██████▍   | 16/25 [01:48<00:51,  5.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  68%|██████▊   | 17/25 [01:58<00:57,  7.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  72%|███████▏  | 18/25 [02:07<00:53,  7.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  76%|███████▌  | 19/25 [02:15<00:46,  7.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  80%|████████  | 20/25 [02:20<00:34,  6.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  84%|████████▍ | 21/25 [02:31<00:33,  8.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  88%|████████▊ | 22/25 [02:37<00:22,  7.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  92%|█████████▏| 23/25 [02:42<00:13,  6.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles:  96%|█████████▌| 24/25 [02:47<00:06,  6.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Processing articles: 100%|██████████| 25/25 [02:57<00:00,  7.09s/it]\n",
      "INFO:embedding_ops:Successfully created knowledge base at ./data/knowledge_base.csv\n",
      "Using venice for chunk analysis\n",
      "INFO:run:Using venice for chunk analysis\n",
      "Using venice for final summary\n",
      "INFO:run:Using venice for final summary\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:inference_ops:Processing text chunks\n",
      "INFO:inference_ops:Summarizing 94 valid chunks of text\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  1%|          | 1/94 [00:33<51:52, 33.47s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 3/94 [00:44<19:19, 12.74s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  5%|▌         | 5/94 [00:48<10:34,  7.13s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  6%|▋         | 6/94 [00:53<09:51,  6.72s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  7%|▋         | 7/94 [01:05<11:50,  8.17s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|▉         | 9/94 [01:28<13:36,  9.60s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 11%|█         | 10/94 [01:32<11:39,  8.33s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 12%|█▏        | 11/94 [01:42<12:02,  8.71s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 13%|█▎        | 12/94 [02:18<21:39, 15.85s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 14%|█▍        | 13/94 [02:21<16:46, 12.43s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 15%|█▍        | 14/94 [02:31<15:47, 11.84s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 16%|█▌        | 15/94 [02:59<21:30, 16.33s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 17%|█▋        | 16/94 [03:19<22:35, 17.38s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 18%|█▊        | 17/94 [03:39<23:29, 18.31s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 19%|█▉        | 18/94 [03:53<21:36, 17.06s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 19/94 [04:05<19:11, 15.35s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 21%|██▏       | 20/94 [04:28<21:42, 17.60s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 22%|██▏       | 21/94 [04:35<17:50, 14.66s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 23%|██▎       | 22/94 [04:38<13:13, 11.01s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.874991 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 24%|██▍       | 23/94 [04:58<16:15, 13.74s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 26%|██▌       | 24/94 [05:00<12:07, 10.40s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 27%|██▋       | 25/94 [05:08<11:05,  9.65s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 28%|██▊       | 26/94 [05:34<16:16, 14.37s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 29%|██▊       | 27/94 [05:59<19:44, 17.68s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|██▉       | 28/94 [06:06<15:52, 14.44s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 31%|███       | 29/94 [06:07<11:25, 10.54s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 32%|███▏      | 30/94 [06:17<10:54, 10.23s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.977822 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 31/94 [06:32<12:09, 11.57s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 32/94 [06:35<09:18,  9.01s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 35%|███▌      | 33/94 [07:06<16:05, 15.82s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 36%|███▌      | 34/94 [07:20<15:05, 15.09s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 37%|███▋      | 35/94 [07:22<11:09, 11.34s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 38%|███▊      | 36/94 [07:47<14:41, 15.20s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 39%|███▉      | 37/94 [07:48<10:27, 11.00s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 38/94 [07:53<08:35,  9.21s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 41%|████▏     | 39/94 [07:57<07:05,  7.74s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 43%|████▎     | 40/94 [08:19<10:48, 12.01s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 44%|████▎     | 41/94 [08:39<12:41, 14.36s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 45%|████▍     | 42/94 [08:39<08:46, 10.12s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.965320 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 46%|████▌     | 43/94 [09:13<14:43, 17.33s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 47%|████▋     | 44/94 [09:31<14:23, 17.27s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 48%|████▊     | 45/94 [09:50<14:44, 18.05s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 49%|████▉     | 46/94 [09:56<11:20, 14.19s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 47/94 [09:57<08:04, 10.31s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 51%|█████     | 48/94 [10:00<06:15,  8.17s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 52%|█████▏    | 49/94 [10:24<09:48, 13.08s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 53%|█████▎    | 50/94 [10:28<07:24, 10.09s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 54%|█████▍    | 51/94 [10:39<07:32, 10.53s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 55%|█████▌    | 52/94 [10:54<08:10, 11.67s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 56%|█████▋    | 53/94 [11:14<09:46, 14.30s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 57%|█████▋    | 54/94 [11:19<07:38, 11.47s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 59%|█████▊    | 55/94 [11:29<07:14, 11.15s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|█████▉    | 56/94 [11:47<08:17, 13.09s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 61%|██████    | 57/94 [11:48<05:55,  9.61s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 62%|██████▏   | 58/94 [11:55<05:10,  8.64s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 63%|██████▎   | 59/94 [12:07<05:44,  9.85s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 64%|██████▍   | 60/94 [12:24<06:43, 11.87s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 65%|██████▍   | 61/94 [12:26<04:55,  8.97s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 66%|██████▌   | 62/94 [12:27<03:30,  6.58s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 67%|██████▋   | 63/94 [12:44<04:57,  9.61s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 68%|██████▊   | 64/94 [12:49<04:08,  8.27s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 69%|██████▉   | 65/94 [12:57<03:58,  8.23s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 66/94 [13:22<06:08, 13.17s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 71%|███████▏  | 67/94 [13:22<04:11,  9.32s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 72%|███████▏  | 68/94 [13:25<03:10,  7.33s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 73%|███████▎  | 69/94 [13:34<03:15,  7.83s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 74%|███████▍  | 70/94 [13:42<03:11,  7.99s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 76%|███████▌  | 71/94 [13:48<02:47,  7.29s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 77%|███████▋  | 72/94 [13:58<03:02,  8.27s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 78%|███████▊  | 73/94 [14:02<02:21,  6.76s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 79%|███████▊  | 74/94 [14:17<03:05,  9.29s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|███████▉  | 75/94 [14:22<02:35,  8.17s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 81%|████████  | 76/94 [14:26<02:04,  6.91s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 82%|████████▏ | 77/94 [14:37<02:17,  8.06s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 83%|████████▎ | 78/94 [14:45<02:06,  7.88s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 84%|████████▍ | 79/94 [15:02<02:40, 10.73s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 85%|████████▌ | 80/94 [15:17<02:48, 12.05s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 86%|████████▌ | 81/94 [16:00<04:37, 21.36s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 87%|████████▋ | 82/94 [16:19<04:07, 20.59s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 88%|████████▊ | 83/94 [16:21<02:45, 15.04s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 89%|████████▉ | 84/94 [16:49<03:09, 18.96s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 85/94 [16:52<02:06, 14.08s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 91%|█████████▏| 86/94 [17:13<02:08, 16.10s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 93%|█████████▎| 87/94 [17:13<01:19, 11.35s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.903355 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 94%|█████████▎| 88/94 [17:27<01:13, 12.27s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 95%|█████████▍| 89/94 [17:41<01:03, 12.77s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 96%|█████████▌| 90/94 [17:43<00:37,  9.32s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 91/94 [17:44<00:21,  7.07s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 98%|█████████▊| 92/94 [17:53<00:14,  7.49s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.958968 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 99%|█████████▉| 93/94 [18:13<00:11, 11.31s/it]INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 94/94 [18:55<00:00, 12.08s/it]\n",
      "INFO:inference_ops:Generating final summary\n",
      "INFO:httpx:HTTP Request: POST https://api.venice.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Summary generated successfully\n",
      "INFO:run:Summary generated successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Temporal Overview\n",
      "Time Range: 2024-12-27 03:18:30 to 2024-12-29 12:15:44\n",
      "Active Periods: \n",
      "- Key activity spikes were observed on December 27, 06:57:27, with the sharing of a list of URLs, possibly indicating sources of information or tools related to mapping and tracking.\n",
      "- Another spike occurred on December 28, 05:20:57, with a post discussing Elon Musk's alleged intentional change of discourse to favor Indian immigration using leftist tactics.\n",
      "- A third spike was observed on December 28, 14:35:24, with a post questioning the credibility of skilled foreign labor from China.\n",
      "Thread Distribution: Threads were primarily focused on topics such as immigration policies, foreign labor credibility, and potential biases in hiring practices.\n",
      "Key Correlations: \n",
      "- The discussion around Elon Musk's alleged support for Indian immigration was correlated with conversations about racism and sexism in hiring practices.\n",
      "- The topic of foreign labor credibility was linked to concerns about the quality of skilled workers from China.\n",
      "\n",
      "### 2. Thread Analysis\n",
      "#### A. Key Metrics\n",
      "[Activity & Reach]\n",
      "- (2024-12-27 06:57:27, \"URL Sharing\", activity_rate, 1.00, 1.00)\n",
      "- (2024-12-28 05:20:57, \"Musk Immigration\", cross_thread_spread, 0.70, 0.80)\n",
      "- (2024-12-28 14:35:24, \"Foreign Labor Credibility\", activity_rate, 1.00, 1.00)\n",
      "[Impact & Quality]\n",
      "- (2024-12-28 05:20:57, \"Musk Immigration\", influence_score, 0.75, 0.85)\n",
      "- (2024-12-28 14:35:24, \"Foreign Labor Credibility\", toxicity_level, 0.90, 0.95)\n",
      "- (2024-12-29 10:07:20, \"Chinese Labor Question\", information_novelty, 0.80, 0.90)\n",
      "\n",
      "#### B. Pattern Summary\n",
      "* Activity: The sequence of events suggests a growing interest in topics related to immigration policies and foreign labor credibility.\n",
      "* Influence: The discussion around Elon Musk's alleged support for Indian immigration had a moderate impact on the conversation.\n",
      "* Credibility: The credibility of sources varied across threads, with some posts providing no specific evidence or sources to back up claims.\n",
      "* Anomalies: The high toxicity level in the \"Foreign Labor Credibility\" thread stands out as an unusual pattern.\n",
      "\n",
      "### 3. Content Analysis\n",
      "#### A. Key Claims\n",
      "[Primary Claims]\n",
      "- (2024-12-28 05:20:57, \"Musk Immigration\", claim, 0.75, 0.85) - Elon Musk is intentionally changing the discourse to favor Indian immigration using leftist tactics.\n",
      "- Supporting evidence: Linked to discussions about racism and sexism in hiring practices.\n",
      "- Cross-references: Connected to conversations about foreign labor credibility.\n",
      "[Risk Factors]\n",
      "* Toxicity: The \"Foreign Labor Credibility\" thread exhibited high toxicity levels.\n",
      "* Community: Response patterns indicated a mix of skepticism and concern regarding immigration policies and foreign labor credibility.\n",
      "* Moderation: Intervention needs were noted in threads with high toxicity levels.\n",
      "\n",
      "#### B. Viral Assessment\n",
      "* Spread Rate: (\"Musk Immigration\", velocity, 0.70)\n",
      "* Catalysts: Linked to trigger events such as the sharing of URLs and discussions about foreign labor credibility.\n",
      "* Cross-Platform: No external signals were observed.\n",
      "\n",
      "### 4. Forecasts\n",
      "#### A. 24h Outlook\n",
      "[Activity]\n",
      "- (2024-12-30 12:15:44, \"Immigration Policy Discussion\", p, [0.60, 0.80])\n",
      "- Expected triggers and impacts include continued discussions around immigration policies and foreign labor credibility.\n",
      "\n",
      "[Risk]\n",
      "- (2024-12-30 12:15:44, \"Toxicity Escalation\", p, [0.40, 0.60])\n",
      "- Potential escalation paths include increased toxicity levels in threads discussing sensitive topics.\n",
      "\n",
      "#### B. 72h Trends\n",
      "[Patterns]\n",
      "- (2024-01-01 12:15:44, \"Immigration Policy Trend\", p, [0.50, 0.70])\n",
      "- Pattern evolution forecast suggests a continued focus on immigration policies and foreign labor credibility.\n",
      "\n",
      "[Interventions]\n",
      "* Recommended Points: Linked to specific events such as the sharing of URLs and discussions about foreign labor credibility.\n",
      "* Stability Metrics: Based on event patterns, stability is expected to be moderate.\n",
      "* Uncertainty Factors: Note event dependencies such as the potential impact of external signals on the conversation.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"<temporal_context>\n",
    "- Real-time Market Dynamics (past 24 hours): Capture price movements, volume patterns, and sentiment shifts\n",
    "- Short-term Trends (past 72 hours): Track momentum and narrative development\n",
    "- Medium-term Patterns (past 7 days): Identify market regime changes and sector rotations\n",
    "- Long-term Context (past 30 days): Establish baseline market conditions and macro trends\n",
    "</temporal_context>\n",
    "\n",
    "<focus_areas>\n",
    "1. Market Structure Analysis:\n",
    "   - Liquidity conditions and market depth\n",
    "   - Institutional vs retail flow patterns\n",
    "   - Cross-asset correlations\n",
    "   - Market microstructure changes\n",
    "\n",
    "2. Risk-Return Dynamics:\n",
    "   - Volatility term structure\n",
    "   - Risk premium evolution\n",
    "   - Systematic risk factors\n",
    "   - Market inefficiencies and anomalies\n",
    "\n",
    "3. Sentiment & Positioning:\n",
    "   - Crowd sentiment metrics\n",
    "   - Positioning extremes\n",
    "   - Narrative momentum\n",
    "   - Consensus divergence\n",
    "\n",
    "4. Macro Environment:\n",
    "   - Monetary policy expectations\n",
    "   - Fiscal policy impacts\n",
    "   - Global capital flows\n",
    "   - Regulatory landscape shifts\n",
    "\n",
    "5. Innovation & Disruption:\n",
    "   - Technology adoption curves\n",
    "   - Business model evolution\n",
    "   - Industry value chain shifts\n",
    "   - Competitive dynamics\n",
    "</focus_areas>\n",
    "\n",
    "<analysis_requirements>\n",
    "1. Signal Extraction:\n",
    "   - Price-volume relationships\n",
    "   - Sentiment-flow correlations\n",
    "   - Cross-sectional patterns\n",
    "   - Regime change indicators\n",
    "\n",
    "2. Risk Assessment:\n",
    "   - Tail risk probabilities\n",
    "   - Correlation breakdowns\n",
    "   - Liquidity conditions\n",
    "   - Systemic risk factors\n",
    "\n",
    "3. Opportunity Identification:\n",
    "   - Value-momentum divergence\n",
    "   - Narrative-price disconnects\n",
    "   - Structural inefficiencies\n",
    "   - Mean reversion potential\n",
    "\n",
    "4. Forecast Parameters:\n",
    "   - Confidence intervals by timeframe\n",
    "   - Scenario probabilities\n",
    "   - Position sizing signals\n",
    "   - Risk-adjusted return expectations\n",
    "</analysis_requirements>\"\"\"\n",
    "\n",
    "providers = {\n",
    "    ModelOperation.EMBEDDING: ModelProvider.OPENAI,\n",
    "    ModelOperation.CHUNK_GENERATION: ModelProvider.VENICE,\n",
    "    ModelOperation.SUMMARIZATION: ModelProvider.VENICE\n",
    "}\n",
    "\n",
    "chunks, summary = run_knowledge_agents(\n",
    "    query=query,\n",
    "    process_new=True,\n",
    "    providers=providers\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
